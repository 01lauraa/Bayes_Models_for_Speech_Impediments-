knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(rstan)
library(bcogsci)
library(extraDistr)
library(knitr)
library(kableExtra)
library(DiagrammeR)
install.packages("DiagrammeR")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(rstan)
library(bcogsci)
library(extraDistr)
library(knitr)
library(kableExtra)
library(DiagrammeR)
library(tibble)
library(stats)
library(bayesplot)
library(ggplot2)
options(mc.cores = parallel::detectCores())
categorical_responses <- data.frame(
Response_Category = c(
"Successful recall",
"Intrusion error",
"Positional misplacement",
"Item omission",
"False recall"
),
Description = c(
"The correct item is recalled in the correct position",
"Item not on the list is recalled",
"Correct item is recalled in the wrong position",
"The item is not recalled at all",
"Item is recalled incorrectly and unrelated to the distractor"
)
)
parameters <- data.frame(
Params = c("a", "t", "f", "c"),
Description = c(
"Probability of correct encoding",
"Probability of encoding the correct item",
"Probability of correct positional encoding",
"Probability of successful recall"
)
)
print(categorical_responses)
print(parameters)
tree_model <- "
digraph MPT_Serial_Recall {
graph [layout = dot, rankdir = TB]
node [shape = ellipse, style = filled, color = lightblue]
Attention  [label = 'Attention Allocation']
Encoding   [label = 'Serial Position Encoding']
Interference [label = 'Interference Management']
Retention  [label = 'Short-term memory retention']
SR [label = 'Successful Recall', shape = box, color = green3]
PME [label = 'Positionally misplaced encoding', shape = box, color = yellow]
IE [label = 'Intrusion Error', shape = box, color = pink]
OM [label = 'Omission', shape = box, color = grey]
FR [label = 'False Recall', shape = box, color = khaki1]
Attention -> Interference [label = 'Correctly Encoded (a)']
Attention -> OM [label = 'Failed to Encode (1 - a)']
Interference -> Encoding [label = 'Correct item under interference (t)']
Interference -> IE [label = 'Intrusion Error (1 - t)']
Encoding -> Retention [label = 'Positionally correct encoding (f)']
Encoding -> PME [label = 'Positionally misplaced encoding (1 - f)']
Retention -> SR [label = 'Successful Recall (c)']
Retention -> FR [label = 'False Recall (1 - c)']
}
"
DiagrammeR::grViz(tree_model)
set.seed(1)
PR_OM <- function(a, t, f, c)
(1 - a)
PR_IE <- function(a, t, f, c)
a * (1 - t)
PR_PME <- function(a, t, f, c)
a * t * (1 - f)
PR_FR <- function(a, t, f, c)
a * t * f * (1 - c)
PR_SR <- function(a, t, f, c)
a * t * f * c
# something to consider is the formulation of the task, for now we only simulate data for number of trials, number of participants, intensity of the distraction present, complexity and the length of the sequence and the sequence id - for hierarchical models we could simulate some info about the participants
# for now just simulate with 1 participant and 50 trials
# our response and stan model however rely on items, not trials so I kept the sequence length constant
a_true <- 0.9
t_true <- 0.8
f_true <- 0.3
alpha_c <- 0.3
beta_c <- -0.2
N_trials <- 50
N_participants <- 10
intensity <- round(runif(N_trials, 0, 1), 2)
complexity <- sample(1:5, N_trials, replace = TRUE)
seq_id <- 1:N_trials
seq_length <- 5
logit <- function(p) {
log(p / (1 - p))}
plogis <- function(x) {
1 / (1 + exp(-x))}
c_prime <- alpha_c + beta_c * intensity
c_true <- plogis(c_prime)
all_data <- data.frame()
for (i in 1:N_trials) {
trial <- list(
sequence_id = seq_id[i],
sequence_length = seq_length,
complexity = complexity[i],
distractor_intensity = intensity[i],
participant_id = 1  #one participant
)
c_true_trial <- plogis(logit(alpha_c) + beta_c * trial$distractor_intensity)
theta_OM <- PR_OM(a_true, t_true, f_true, c_true_trial)
theta_IE <- PR_IE(a_true, t_true, f_true, c_true_trial)
theta_PME <- PR_PME(a_true, t_true, f_true, c_true_trial)
theta_FR <- PR_FR(a_true, t_true, f_true, c_true_trial)
theta_SR <- PR_SR(a_true, t_true, f_true, c_true_trial)
theta_itm <- c(theta_SR, theta_FR, theta_PME, theta_IE, theta_OM)
for (pos in 1:5) {
resp <- sample(1:5, 1, prob = theta_itm)
all_data <- rbind(all_data, data.frame(
sequence_id = trial$sequence_id,
sequence_length = seq_length,
complexity = trial$complexity,
distractor_intensity = trial$distractor_intensity,
participant_id = trial$participant_id,
position_in_sequence = pos,
response_category = resp
))
}
}
intensities <- all_data %>%
group_by(sequence_id) %>%
summarize(distractor_intensity = first(distractor_intensity)) %>%
select(distractor_intensity) %>%
pull(distractor_intensity)
print(head(all_data))
data_srecall <- list(N_trials = N_trials,
resp = all_data$response_category,
intensity = all_data$distractor_intensity,
seq_length = seq_length)
fit_srecall <- stan('serial_recall.stan', data= data_srecall)
as.data.frame(fit_srecall) %>%
select(c("a","t","f")) %>%
mcmc_recover_hist(true = c(a_true, t_true, f_true)) +
coord_cartesian(xlim = c(0, 1))
as.data.frame(fit_srecall) %>%
select(c("alpha_c", "beta_c")) %>%
mcmc_recover_hist(true = c(alpha_c, beta_c)) +
coord_cartesian(xlim = c(-1, 1))
print(fit_srecall, pars= c('a', 't', 'f', 'alpha_c', 'beta_c'))
post_data <- rstan::extract(fit_srecall)$pred_resp[1,]
post_data <- as.matrix(t(post_data))
ppc_bars(all_data$response_category, post_data) +
ggtitle('Posterior predictive distribution')
data("df_schizophrenia")
?df_schizophrenia
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(rstan)
library(bcogsci)
library(extraDistr)
library(knitr)
library(kableExtra)
library(DiagrammeR)
library(tibble)
library(stats)
library(bayesplot)
library(ggplot2)
options(mc.cores = parallel::detectCores())
library(dplyr)
library(rstan)
options(mc.cores = parallel::detectCores())
library(bcogsci)
library(extraDistr)
library(bayesplot)
library(ggplot2)
library(tidyr)
data("df_schizophrenia")
#19.2
data("df_schizophrenia")
ls <- list(patient = df_schizophrenia$patient,
subj = df_schizophrenia$subj,
rt = df_schizophrenia$rt,
N = nrow(df_schizophrenia),
N_subj = max(df_schizophrenia$subj)
)
View(df_schizophrenia)
